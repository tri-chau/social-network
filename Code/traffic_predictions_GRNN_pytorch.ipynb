{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc từng file từ thư mục MXH_Dataset\n",
    "train_df = pd.read_csv(\"../Dataset/train.csv\")\n",
    "segment_status_df = pd.read_csv(\"../Dataset/segment_status.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_status: <bound method DataFrame.info of          _id                updated_at  segment_id  velocity\n",
      "0          0  2020-07-03T14:55:31.869Z       24845        20\n",
      "1          1  2020-07-03T15:02:56.048Z       33923        10\n",
      "2          2  2020-07-04T08:15:52.696Z       33824         5\n",
      "3          3  2020-07-04T08:15:59.903Z       33824         5\n",
      "4          4  2020-07-04T08:16:08.201Z       33824         5\n",
      "...      ...                       ...         ...       ...\n",
      "90933  90933  2021-04-22T06:52:39.280Z       52247         1\n",
      "90934  90934  2021-04-22T06:52:52.501Z       52247         1\n",
      "90935  90935  2021-04-22T06:53:02.335Z       52247         1\n",
      "90936  90936  2021-04-22T06:53:14.294Z       52247         1\n",
      "90937  90937  2021-04-22T06:53:27.300Z       52247         1\n",
      "\n",
      "[90938 rows x 4 columns]>\n",
      "train: <bound method DataFrame.info of          _id  segment_id        date  weekday        period LOS   s_node_id  \\\n",
      "0          0          26  2021-04-16        4   period_0_30   A   366428456   \n",
      "1          1          33  2020-08-02        6  period_23_30   C   366469460   \n",
      "2          2          33  2020-08-03        0   period_0_00   D   366469460   \n",
      "3          3          67  2021-03-09        1   period_9_30   B   366403668   \n",
      "4          4          67  2021-03-23        1   period_9_30   B   366403668   \n",
      "...      ...         ...         ...      ...           ...  ..         ...   \n",
      "33436  33436       84529  2021-01-05        1   period_8_00   F   411918572   \n",
      "33437  33437       84533  2021-01-09        5  period_13_30   F  4597281310   \n",
      "33438  33438       84533  2021-04-22        3   period_5_00   F  4597281310   \n",
      "33439  33439       84534  2021-01-09        5  period_13_30   D   411918528   \n",
      "33440  33440       84535  2021-01-09        5  period_13_30   F  5140843585   \n",
      "\n",
      "        e_node_id  length  street_id  max_velocity  street_level  \\\n",
      "0       366416066     116   32575820           NaN             4   \n",
      "1      3792257828      26   32575862           NaN             3   \n",
      "2      3792257828      26   32575862           NaN             3   \n",
      "3      5755066033       7   32575862           NaN             3   \n",
      "4      5755066033       7   32575862           NaN             3   \n",
      "...           ...     ...        ...           ...           ...   \n",
      "33436  1226517262      13  654864528           NaN             2   \n",
      "33437   411918528     126  654864530           NaN             4   \n",
      "33438   411918528     126  654864530           NaN             4   \n",
      "33439   411925985      89  654864530           NaN             4   \n",
      "33440  6150226443     139  656562463           NaN             4   \n",
      "\n",
      "                street_name   street_type  long_snode  lat_snode  long_enode  \\\n",
      "0             Nguyễn Văn Bá      tertiary  106.768732  10.841506  106.769254   \n",
      "1                Đường số 5     secondary  106.761957  10.878650  106.762143   \n",
      "2                Đường số 5     secondary  106.761957  10.878650  106.762143   \n",
      "3                Đường số 5     secondary  106.768412  10.880817  106.768461   \n",
      "4                Đường số 5     secondary  106.768412  10.880817  106.768461   \n",
      "...                     ...           ...         ...        ...         ...   \n",
      "33436  Nguyễn Thị Minh Khai       primary  106.704503  10.789614  106.704584   \n",
      "33437     Nguyễn Bỉnh Khiêm      tertiary  106.704986  10.787267  106.704149   \n",
      "33438     Nguyễn Bỉnh Khiêm      tertiary  106.704986  10.787267  106.704149   \n",
      "33439     Nguyễn Bỉnh Khiêm      tertiary  106.704149  10.788051  106.703549   \n",
      "33440                   NaN  unclassified  106.828885  10.694142  106.827709   \n",
      "\n",
      "       lat_enode  \n",
      "0      10.842422  \n",
      "1      10.878808  \n",
      "2      10.878808  \n",
      "3      10.880771  \n",
      "4      10.880771  \n",
      "...          ...  \n",
      "33436  10.789702  \n",
      "33437  10.788051  \n",
      "33438  10.788051  \n",
      "33439  10.788604  \n",
      "33440  10.693657  \n",
      "\n",
      "[33441 rows x 18 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số dòng, số cột của từng file\n",
    "for name, df in [(\"segment_status\", segment_status_df), \n",
    "                 (\"train\", train_df)]:\n",
    "    print(f\"{name}: {df.info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Xử lý dữ liệu thiếu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_df:\n",
      " _id                 0\n",
      "segment_id          0\n",
      "date                0\n",
      "weekday             0\n",
      "period              0\n",
      "LOS                 0\n",
      "s_node_id           0\n",
      "e_node_id           0\n",
      "length              0\n",
      "street_id           0\n",
      "max_velocity    28495\n",
      "street_level        0\n",
      "street_name         1\n",
      "street_type         0\n",
      "long_snode          0\n",
      "lat_snode           0\n",
      "long_enode          0\n",
      "lat_enode           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in train_df:\\n\", train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_df:\n",
      " _id             0\n",
      "segment_id      0\n",
      "date            0\n",
      "weekday         0\n",
      "period          0\n",
      "LOS             0\n",
      "s_node_id       0\n",
      "e_node_id       0\n",
      "length          0\n",
      "street_id       0\n",
      "max_velocity    0\n",
      "street_level    0\n",
      "street_name     0\n",
      "street_type     0\n",
      "long_snode      0\n",
      "lat_snode       0\n",
      "long_enode      0\n",
      "lat_enode       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Xử lý giá trị thiếu\n",
    "train_df['max_velocity'] = train_df['max_velocity'].fillna(train_df['max_velocity'].mean())\n",
    "train_df['street_name'] = train_df['street_name'].fillna('Unknown')\n",
    "\n",
    "print(\"Missing values in train_df:\\n\", train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi thời gian\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "segment_status_df['updated_at'] = pd.to_datetime(segment_status_df['updated_at'])\n",
    "train_df = train_df.sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Chuẩn hóa cột LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['LOS_encoded'] = le.fit_transform(train_df['LOS'])\n",
    "scaler = MinMaxScaler()\n",
    "train_df['LOS_norm'] = scaler.fit_transform(train_df[['LOS_encoded']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Tạo đặc trưng nút"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = train_df[['s_node_id', 'e_node_id', 'segment_id']].drop_duplicates().dropna().astype(int)\n",
    "# Trước khi tạo edge_index_torch\n",
    "node_ids = sorted(set(edge_index['s_node_id']).union(edge_index['e_node_id']))\n",
    "node_id_to_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
    "num_nodes = len(node_ids)\n",
    "\n",
    "# Cập nhật edge_index với chỉ số mới\n",
    "edge_index['s_node_idx'] = edge_index['s_node_id'].map(node_id_to_index)\n",
    "edge_index['e_node_idx'] = edge_index['e_node_id'].map(node_id_to_index)\n",
    "edge_index_torch = torch.tensor(edge_index[['s_node_idx', 'e_node_idx']].T.values, dtype=torch.int64)\n",
    "\n",
    "# Tính số nút\n",
    "num_nodes = len(set(edge_index['s_node_id']).union(edge_index['e_node_id']))\n",
    "\n",
    "# Tạo đặc trưng nút\n",
    "node_degrees = pd.concat([\n",
    "    edge_index['s_node_id'].value_counts(),\n",
    "    edge_index['e_node_id'].value_counts()\n",
    "]).groupby(level=0).sum().reindex(range(num_nodes), fill_value=0).values\n",
    "\n",
    "node_features = []\n",
    "for node_id in range(num_nodes):\n",
    "    connected_edges = edge_index[\n",
    "        (edge_index['s_node_id'] == node_id) | (edge_index['e_node_id'] == node_id)\n",
    "    ]\n",
    "    segment_ids = connected_edges['segment_id']\n",
    "    if len(segment_ids) > 0:\n",
    "        segment_data = train_df[train_df['segment_id'].isin(segment_ids)]\n",
    "        avg_length = segment_data['length'].mean() if 'length' in segment_data else 0\n",
    "        avg_velocity = segment_data['velocity'].mean() if 'velocity' in segment_data else 0\n",
    "    else:\n",
    "        avg_length, avg_velocity = 0, 0\n",
    "    node_features.append([node_degrees[node_id], avg_length, avg_velocity])\n",
    "\n",
    "node_features = torch.tensor(node_features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Merge 2 file segment_status và train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm convert period (vd: \"period_14_30\") thành timedelta\n",
    "def period_to_time(period_str):\n",
    "    try:\n",
    "        _, hour_str, min_str = period_str.split(\"_\")\n",
    "        hour = int(hour_str)\n",
    "        minute = int(min_str)\n",
    "        return pd.to_timedelta(f\"{hour}:{minute}:00\")\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "# Apply và tạo cột thời gian đầy đủ\n",
    "train_df['time_delta'] = train_df['period'].apply(period_to_time)\n",
    "train_df['date'] = pd.to_datetime(train_df['date']) + train_df['time_delta']\n",
    "\n",
    "# Xoá cột phụ nếu muốn\n",
    "train_df.drop(columns='time_delta', inplace=True)\n",
    "\n",
    "# Chuyển 'date' và 'updated_at' về datetime\n",
    "train_df['date'] = pd.to_datetime(train_df['date']).dt.tz_localize(None)\n",
    "segment_status_df['updated_at'] = pd.to_datetime(segment_status_df['updated_at']).dt.tz_localize(None)\n",
    "\n",
    "# Sort trước khi dùng merge_asof\n",
    "train = train_df.sort_values(by='date')\n",
    "segment_status = segment_status_df.sort_values(by='updated_at')\n",
    "\n",
    "# Merge gần đúng theo thời gian, trong cùng segment_id\n",
    "merged_df = pd.merge_asof(\n",
    "    train,\n",
    "    segment_status,\n",
    "    by='segment_id',\n",
    "    left_on='date',\n",
    "    right_on='updated_at',\n",
    "    direction='nearest',  # hoặc 'backward' nếu bạn chỉ muốn dùng dữ liệu trước đó\n",
    "    tolerance=pd.Timedelta('30min')  # chỉ chấp nhận khớp nếu lệch thời gian <= 30 phút\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Tạo pivot table cho LOS_norm và velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17560\\865394265.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ).fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).sort_index(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Tạo los_pivot\n",
    "los_pivot = train_df.pivot_table(\n",
    "    index='segment_id',\n",
    "    columns='date',\n",
    "    values='LOS_norm',\n",
    "    aggfunc='mean'\n",
    ").fillna(method='ffill', axis=1).fillna(method='bfill', axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Tạo danh sách data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: DataBatch(x=[11314, 3], edge_index=[2, 10027], edge_attr=[10027, 1], y=[10027, 1], batch=[11314], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "# Tạo danh sách Data objects\n",
    "data_list = []\n",
    "for date in los_pivot.columns:\n",
    "    edge_features = []\n",
    "    targets = []\n",
    "    for _, row in edge_index.iterrows():\n",
    "        segment_id = row['segment_id']\n",
    "        if segment_id in los_pivot.index:\n",
    "            los = los_pivot.loc[segment_id, date]\n",
    "            edge_features.append([los])\n",
    "            targets.append([los])\n",
    "        else:\n",
    "            edge_features.append([0])\n",
    "            targets.append([0])\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float32)\n",
    "    targets = torch.tensor(targets, dtype=torch.float32)\n",
    "    data = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index_torch,\n",
    "        edge_attr=edge_features,\n",
    "        y=targets\n",
    "    )\n",
    "    data_list.append(data)\n",
    "\n",
    "# Tạo DataLoader\n",
    "loader = DataLoader(data_list, batch_size=4, shuffle=False)\n",
    "\n",
    "# Kiểm tra DataLoader\n",
    "for data in loader:\n",
    "    print(f\"Data: {data}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Định nghĩa mô hình GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRNN(nn.Module):\n",
    "    def __init__(self, node_features_dim, hidden_dim, out_dim):\n",
    "        super(GRNN, self).__init__()\n",
    "        self.gcn = GCNConv(node_features_dim, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data_list):\n",
    "        outputs = []\n",
    "        h = None\n",
    "        for data in data_list:\n",
    "            x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "            x = torch.relu(self.gcn(x, edge_index, edge_attr))\n",
    "            x = x.unsqueeze(0)  # [1, num_nodes, hidden_dim]\n",
    "            x, h = self.rnn(x, h)\n",
    "            x = x.squeeze(0)  # [num_nodes, hidden_dim]\n",
    "            out = self.fc(x)  # [num_nodes, out_dim]\n",
    "            outputs.append(out[data.edge_index[0]])  # Dự đoán cho cạnh\n",
    "        return outputs\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = GRNN(node_features_dim=3, hidden_dim=32, out_dim=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.12195290588453168\n",
      "Epoch 2, Loss: 0.11983358572985305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model([data])\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs[\u001b[38;5;241m0\u001b[39m], data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Huấn luyện\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model([data])\n",
    "        loss = criterion(outputs[0], data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        outputs = model([data])\n",
    "        predictions.append(outputs[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá\n",
    "targets = [data.y.cpu().numpy() for data in loader]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(np.concatenate(targets), np.concatenate(predictions))\n",
    "print(f\"Test MSE: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
