{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7643cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3884\\356803532.py\", line 5, in <module>\n",
      "    from torch_geometric.utils import to_networkx\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\__init__.py\", line 21, in <module>\n",
      "    import torch_geometric.datasets\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\datasets\\__init__.py\", line 18, in <module>\n",
      "    from .qm9 import QM9\n",
      "  File \"C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\datasets\\qm9.py\", line 22, in <module>\n",
      "    conversion = torch.tensor([\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\datasets\\qm9.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  conversion = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21413121",
   "metadata": {},
   "source": [
    "## 1. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d24fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc từng file từ thư mục MXH_Dataset\n",
    "train_df = pd.read_csv(\"../Dataset/train.csv\")\n",
    "segment_status_df = pd.read_csv(\"../Dataset/segment_status.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9ede70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment_status: <bound method DataFrame.info of          _id                updated_at  segment_id  velocity\n",
      "0          0  2020-07-03T14:55:31.869Z       24845        20\n",
      "1          1  2020-07-03T15:02:56.048Z       33923        10\n",
      "2          2  2020-07-04T08:15:52.696Z       33824         5\n",
      "3          3  2020-07-04T08:15:59.903Z       33824         5\n",
      "4          4  2020-07-04T08:16:08.201Z       33824         5\n",
      "...      ...                       ...         ...       ...\n",
      "90933  90933  2021-04-22T06:52:39.280Z       52247         1\n",
      "90934  90934  2021-04-22T06:52:52.501Z       52247         1\n",
      "90935  90935  2021-04-22T06:53:02.335Z       52247         1\n",
      "90936  90936  2021-04-22T06:53:14.294Z       52247         1\n",
      "90937  90937  2021-04-22T06:53:27.300Z       52247         1\n",
      "\n",
      "[90938 rows x 4 columns]>\n",
      "train: <bound method DataFrame.info of          _id  segment_id        date  weekday        period LOS   s_node_id  \\\n",
      "0          0          26  2021-04-16        4   period_0_30   A   366428456   \n",
      "1          1          33  2020-08-02        6  period_23_30   C   366469460   \n",
      "2          2          33  2020-08-03        0   period_0_00   D   366469460   \n",
      "3          3          67  2021-03-09        1   period_9_30   B   366403668   \n",
      "4          4          67  2021-03-23        1   period_9_30   B   366403668   \n",
      "...      ...         ...         ...      ...           ...  ..         ...   \n",
      "33436  33436       84529  2021-01-05        1   period_8_00   F   411918572   \n",
      "33437  33437       84533  2021-01-09        5  period_13_30   F  4597281310   \n",
      "33438  33438       84533  2021-04-22        3   period_5_00   F  4597281310   \n",
      "33439  33439       84534  2021-01-09        5  period_13_30   D   411918528   \n",
      "33440  33440       84535  2021-01-09        5  period_13_30   F  5140843585   \n",
      "\n",
      "        e_node_id  length  street_id  max_velocity  street_level  \\\n",
      "0       366416066     116   32575820           NaN             4   \n",
      "1      3792257828      26   32575862           NaN             3   \n",
      "2      3792257828      26   32575862           NaN             3   \n",
      "3      5755066033       7   32575862           NaN             3   \n",
      "4      5755066033       7   32575862           NaN             3   \n",
      "...           ...     ...        ...           ...           ...   \n",
      "33436  1226517262      13  654864528           NaN             2   \n",
      "33437   411918528     126  654864530           NaN             4   \n",
      "33438   411918528     126  654864530           NaN             4   \n",
      "33439   411925985      89  654864530           NaN             4   \n",
      "33440  6150226443     139  656562463           NaN             4   \n",
      "\n",
      "                street_name   street_type  long_snode  lat_snode  long_enode  \\\n",
      "0             Nguyễn Văn Bá      tertiary  106.768732  10.841506  106.769254   \n",
      "1                Đường số 5     secondary  106.761957  10.878650  106.762143   \n",
      "2                Đường số 5     secondary  106.761957  10.878650  106.762143   \n",
      "3                Đường số 5     secondary  106.768412  10.880817  106.768461   \n",
      "4                Đường số 5     secondary  106.768412  10.880817  106.768461   \n",
      "...                     ...           ...         ...        ...         ...   \n",
      "33436  Nguyễn Thị Minh Khai       primary  106.704503  10.789614  106.704584   \n",
      "33437     Nguyễn Bỉnh Khiêm      tertiary  106.704986  10.787267  106.704149   \n",
      "33438     Nguyễn Bỉnh Khiêm      tertiary  106.704986  10.787267  106.704149   \n",
      "33439     Nguyễn Bỉnh Khiêm      tertiary  106.704149  10.788051  106.703549   \n",
      "33440                   NaN  unclassified  106.828885  10.694142  106.827709   \n",
      "\n",
      "       lat_enode  \n",
      "0      10.842422  \n",
      "1      10.878808  \n",
      "2      10.878808  \n",
      "3      10.880771  \n",
      "4      10.880771  \n",
      "...          ...  \n",
      "33436  10.789702  \n",
      "33437  10.788051  \n",
      "33438  10.788051  \n",
      "33439  10.788604  \n",
      "33440  10.693657  \n",
      "\n",
      "[33441 rows x 18 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số dòng, số cột của từng file\n",
    "for name, df in [(\"segment_status\", segment_status_df), \n",
    "                 (\"train\", train_df)]:\n",
    "    print(f\"{name}: {df.info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92e6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_df:\n",
      " _id                 0\n",
      "segment_id          0\n",
      "date                0\n",
      "weekday             0\n",
      "period              0\n",
      "LOS                 0\n",
      "s_node_id           0\n",
      "e_node_id           0\n",
      "length              0\n",
      "street_id           0\n",
      "max_velocity    28495\n",
      "street_level        0\n",
      "street_name         1\n",
      "street_type         0\n",
      "long_snode          0\n",
      "lat_snode           0\n",
      "long_enode          0\n",
      "lat_enode           0\n",
      "dtype: int64\n",
      "Missing values in train_df:\n",
      " _id             0\n",
      "segment_id      0\n",
      "date            0\n",
      "weekday         0\n",
      "period          0\n",
      "LOS             0\n",
      "s_node_id       0\n",
      "e_node_id       0\n",
      "length          0\n",
      "street_id       0\n",
      "max_velocity    0\n",
      "street_level    0\n",
      "street_name     0\n",
      "street_type     0\n",
      "long_snode      0\n",
      "lat_snode       0\n",
      "long_enode      0\n",
      "lat_enode       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in train_df:\\n\", train_df.isnull().sum())\n",
    "# Xử lý giá trị thiếu\n",
    "train_df['max_velocity'] = train_df['max_velocity'].fillna(train_df['max_velocity'].mean())\n",
    "train_df['street_name'] = train_df['street_name'].fillna('Unknown')\n",
    "\n",
    "print(\"Missing values in train_df:\\n\", train_df.isnull().sum())\n",
    "\n",
    "# Chuyển đổi thời gian\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "segment_status_df['updated_at'] = pd.to_datetime(segment_status_df['updated_at'])\n",
    "train_df = train_df.sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfc690",
   "metadata": {},
   "source": [
    "## 2. Chuẩn bị model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb4d5a",
   "metadata": {},
   "source": [
    "### 2.1 Hàm tạo graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9a7aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 122 graphs with max nodes: 2576\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị đồ thị từ train_df\n",
    "def create_graphs(df):\n",
    "    # Lấy danh sách các ngày duy nhất\n",
    "    dates = df['date'].dt.date.unique()\n",
    "    graphs = []\n",
    "    node_encoder = LabelEncoder()\n",
    "    \n",
    "    # Tạo danh sách node duy nhất\n",
    "    all_nodes = pd.concat([df['s_node_id'], df['e_node_id']]).unique()\n",
    "    node_encoder.fit(all_nodes)\n",
    "    \n",
    "    for date in dates:\n",
    "        # Lọc dữ liệu theo ngày\n",
    "        daily_df = df[df['date'].dt.date == date]\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Thêm cạnh (đoạn đường)\n",
    "        for _, row in daily_df.iterrows():\n",
    "            s_node = node_encoder.transform([row['s_node_id']])[0]\n",
    "            e_node = node_encoder.transform([row['e_node_id']])[0]\n",
    "            G.add_edge(s_node, e_node, segment_id=row['segment_id'])\n",
    "        \n",
    "        if G.number_of_edges() > 0:  # Chỉ thêm đồ thị có cạnh\n",
    "            graphs.append(G)\n",
    "    \n",
    "    return graphs, node_encoder\n",
    "\n",
    "graphs, node_encoder = create_graphs(train_df)\n",
    "print(f\"Created {len(graphs)} graphs with max nodes: {max(g.number_of_nodes() for g in graphs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbbd864",
   "metadata": {},
   "source": [
    "### 2.2 Chuẩn bị ma trận kề"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn bị ma trận kề\n",
    "max_nodes = max(g.number_of_nodes() for g in graphs)\n",
    "adj_matrices = []\n",
    "for g in graphs:\n",
    "    adj = nx.adjacency_matrix(g).todense()\n",
    "    # Pad ma trận để có kích thước max_nodes x max_nodes\n",
    "    adj_padded = np.pad(adj, ((0, max_nodes - adj.shape[0]), (0, max_nodes - adj.shape[0])), 'constant')\n",
    "    adj_matrices.append(adj_padded)\n",
    "adj_tensor = torch.tensor(adj_matrices, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db40278",
   "metadata": {},
   "source": [
    "## 3. Định nghĩa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRNN(nn.Module):\n",
    "    def __init__(self, max_nodes, hidden_dim):\n",
    "        super(GraphRNN, self).__init__()\n",
    "        self.max_nodes = max_nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.node_rnn = nn.GRU(input_size=1, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.edge_rnn = nn.GRU(input_size=hidden_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, max_nodes)  # Dự đoán toàn bộ hàng của ma trận kề\n",
    "    \n",
    "    def forward(self, adj_matrix):\n",
    "        batch_size = adj_matrix.size(0)\n",
    "        node_hidden = torch.zeros(1, batch_size, self.hidden_dim).to(adj_matrix.device)\n",
    "        \n",
    "        # Sinh node (giả lập xác suất sinh node)\n",
    "        node_inputs = torch.ones(batch_size, self.max_nodes, 1).to(adj_matrix.device)\n",
    "        node_outputs, _ = self.node_rnn(node_inputs, node_hidden)  # [batch_size, max_nodes, hidden_dim]\n",
    "        \n",
    "        # Sinh ma trận kề đầy đủ\n",
    "        edge_probs = []\n",
    "        for i in range(self.max_nodes):\n",
    "            # Lấy đặc trưng của node i\n",
    "            node_i = node_outputs[:, i, :].unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "            edge_output, node_hidden = self.edge_rnn(node_i, node_hidden)  # [batch_size, 1, hidden_dim]\n",
    "            \n",
    "            # Dự đoán xác suất cạnh từ node i đến tất cả node khác\n",
    "            edge_prob = torch.sigmoid(self.output_layer(edge_output.squeeze(1)))  # [batch_size, max_nodes]\n",
    "            edge_probs.append(edge_prob)\n",
    "        \n",
    "        # Stack để được [batch_size, max_nodes, max_nodes]\n",
    "        edge_probs = torch.stack(edge_probs, dim=1)  # [batch_size, max_nodes, max_nodes]\n",
    "        return edge_probs\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphRNN(max_nodes=max_nodes, hidden_dim=128).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4691df02",
   "metadata": {},
   "source": [
    "## 4. Huấn luyện model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e1488",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([122, 2576, 2576])) that is different to the input size (torch.Size([122, 2576])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m output \u001b[38;5;241m=\u001b[39m model(adj_tensor)\n\u001b[1;32m----> 8\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3087\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3089\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3091\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3092\u001b[0m     )\n\u001b[0;32m   3094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3095\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([122, 2576, 2576])) that is different to the input size (torch.Size([122, 2576])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "adj_tensor = adj_tensor.to(device)\n",
    "losses = []\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(adj_tensor)\n",
    "    print(f\"Epoch {epoch+1} - Output shape: {output.shape}, Target shape: {adj_tensor.shape}\")  # Debug\n",
    "    loss = criterion(output, adj_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3648438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ biểu đồ loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.savefig('graphrnn_loss.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinh đồ thị mới\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_adj = model(torch.zeros(1, max_nodes, max_nodes).to(device))\n",
    "    generated_adj = (generated_adj > 0.5).float().squeeze(0).cpu().numpy()\n",
    "    generated_graph = nx.from_numpy_array(generated_adj)\n",
    "    \n",
    "    # Lưu đồ thị sinh ra\n",
    "    os.makedirs('generated_graphs', exist_ok=True)\n",
    "    nx.write_edgelist(generated_graph, 'generated_graphs/generated_graph.edgelist')\n",
    "    print(f\"Generated graph with {generated_graph.number_of_nodes()} nodes and {generated_graph.number_of_edges()} edges\")\n",
    "\n",
    "# Vẽ đồ thị sinh ra (tùy chọn)\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(generated_graph, with_labels=True, node_color='lightblue', edge_color='gray')\n",
    "plt.savefig('generated_graphs/generated_graph.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
